# 面试
## 1、比赛相关
### 语义分割比赛
#### deeplabv3发展历程
1. deeplabv1
    - 采用vgg16前向计算，减少了后两个池化层以减少图像下采样，为保证视野采用空洞卷积
    - 使用1x1卷积替换全连接层实现全卷积网络
    - 使用条件随机场使得边缘更清晰
    - 多尺寸预测，在每个池化层后面都加一层1x1卷积，类似图像金字塔结构（FCN），得到四个特征图作为预测。
2. deeplabv2
    - 受SPP启发的来ASPP，在最后采用类似inception的结构网络，多分支多样空洞卷积。
3. deeplabv3
    - 使用Multi-Grid策略，即在模型后端多家几层不同rate的空洞卷积，扩大感受野
    - 将batch归一化加入ASPP模块，使得数据训练更加有效
    - DeepLabv3 的 ASPP 加入了 全局池化层+conv1x1+双线性插值上采样 的模块 解决随着特征图的变小，空洞卷积退化为1x1卷积。
4. deeplabv3+
    - 将deeplabv3看成Encoder-Deconder结构
    - 借鉴MobileNet简化卷积
    - 使用修改过的Xception
#### 医学中Unet和Deeplabv3对比
相比于FCN和Deeplab等，UNet共进行了4次上采样，并在同一个stage使用了skip connection，而不是直接在高级语义特征上进行监督和loss反传，这样就保证了最后恢复出来的特征图融合了更多的low-level的feature，也使得不同scale的feature得到了的融合，从而可以进行多尺度预测和DeepSupervision。4次上采样也使得分割图恢复边缘等信息更加精细。

#### 语义分割loss
1. 交叉熵loss
2. 带权交叉熵loss
3. focal loss：解决样本数量不平衡，在二元交叉熵损失前面加参数a的基础上，将高置信度样本的损失降低一些，即动态a
4. Dice Loss：类似交并比结构，使用在样本极度不均衡的情况，如果一般情况下使用Dice Loss会回反向传播有不利的影响，使得训练不稳定。
5. IOU loss：与Dice loss类似，分母不同，略小。
6. Lovasz-Softmax Loss：